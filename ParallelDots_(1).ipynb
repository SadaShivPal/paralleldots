{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "ParallelDots (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcUbaCnAISCM",
        "colab_type": "code",
        "outputId": "1344e053-e4af-4cc2-d014-af71753426e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/warwick_qu_dataset')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /warwick_qu_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu2Gm5kgIQv0",
        "colab_type": "code",
        "outputId": "a8d391d6-f32e-4cee-dc1d-c54ca48f086d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-12 01:05:25--  https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip\n",
            "Resolving warwick.ac.uk (warwick.ac.uk)... 137.205.28.41\n",
            "Connecting to warwick.ac.uk (warwick.ac.uk)|137.205.28.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 \n",
            "Length: 180902609 (173M) [application/zip]\n",
            "Saving to: ‘warwick_qu_dataset_released_2016_07_08.zip’\n",
            "\n",
            "warwick_qu_dataset_ 100%[===================>] 172.52M  10.4MB/s    in 32s     \n",
            "\n",
            "2019-09-12 01:05:58 (5.45 MB/s) - ‘warwick_qu_dataset_released_2016_07_08.zip’ saved [180902609/180902609]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17iRMBIyKY2p",
        "colab_type": "code",
        "outputId": "7b15df9e-d1c9-4852-ca86-be7f947dd268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/warwick_qu_dataset'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRwjMHA_ISOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -q 'warwick_qu_dataset_released_2016_07_08.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFKt0FTBKjgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kOOBZ2tKjuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5BiIs20IDSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import os\n",
        "dirname = \"/content/Warwick QU Dataset (Released 2016_07_08)/\"\n",
        "reshapedirname = \"./reshaped_warwick/\"\n",
        "final_height = 400\n",
        "final_width = 600\n",
        "try:\n",
        "\tos.stat(reshapedirname)\n",
        "except:\n",
        "\tos.mkdir(reshapedirname)\n",
        "for subdirname in [\"segments_train\",\"segments_test\",\"segments_train_eval\",\"images_train\",\"images_test\",\"images_train_eval\"]:\n",
        "\ttry:\n",
        "\t\tos.stat(reshapedirname+subdirname)\n",
        "\texcept:\n",
        "\t\tos.mkdir(reshapedirname+subdirname)\n",
        "prefix_name = [\"images\",\"segments\"]\n",
        "suffix_name = [\"train\",\"test\"]\n",
        "for file in os.listdir(dirname):\n",
        "\tif file.endswith(\".bmp\"):\n",
        "\t\timg = Image.open(dirname+file)\n",
        "\t\twidth, height = img.size\n",
        "\t\tistest,isanno = False,False\n",
        "\t\tif file[:4] == \"test\":\n",
        "\t\t\tistest = True\n",
        "\t\tif file.find(\"anno\") != -1:\n",
        "\t\t\tisanno = True\n",
        "\t\tif isanno:\n",
        "\t\t\t# change the image to saturated\n",
        "\t\t\timg = img.point(lambda i: i * 255)\n",
        "\t\treshaped_image = img = img.resize((final_width, final_height), PIL.Image.ANTIALIAS)\n",
        "\t\tnewfilename = reshapedirname+prefix_name[isanno]+\"_\"+suffix_name[istest]+\"/\"+file.split('.')[0]\n",
        "\t\tnewfilenamefull = newfilename+\".png\"\n",
        "\t\treshaped_image.save(newfilenamefull,\"PNG\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7MV0RL0IDSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data_input import gen_csv_paths\n",
        "\n",
        "gen_csv_paths('reshaped_warwick/', 'train', 0)\n",
        "gen_csv_paths('reshaped_warwick/', 'train', 1)\n",
        "gen_csv_paths('reshaped_warwick/', 'train', 2)\n",
        "gen_csv_paths('reshaped_warwick/', 'train', 3)\n",
        "gen_csv_paths('reshaped_warwick/', 'test')\n",
        "gen_csv_paths('reshaped_warwick/', 'train_eval')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUWyFVa0IDSd",
        "colab_type": "code",
        "outputId": "860fd92b-5218-42c6-8304-833708beda2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "import time\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "import mainutils\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "tf.app.flags.DEFINE_string('train_dir', '/tmp/warwick_train',\n",
        "\t\t\t\t\t\t   \"\"\"Directory where to write event logs \"\"\"\n",
        "\t\t\t\t\t\t   \"\"\"and checkpoint.\"\"\")\n",
        "tf.app.flags.DEFINE_string('eval_data', 'train',\n",
        "\t\t\t\t\t\t   \"\"\"Either 'test' or 'train'.\"\"\")\n",
        "tf.app.flags.DEFINE_integer('max_steps', 4000,\n",
        "\t\t\t\t\t\t\t\"\"\"Number of batches to run.\"\"\")\n",
        "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
        "\t\t\t\t\t\t\t\"\"\"Whether to log device placement.\"\"\")\n",
        "tf.app.flags.DEFINE_integer('log_frequency', 200,\n",
        "\t\t\t\t\t\t\t\"\"\"How often to log results to the console.\"\"\")\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "\n",
        "def train(sessid):\n",
        "\twith tf.Graph().as_default():\n",
        "\t\tckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
        "\t\tglobal_step_init = -1\n",
        "\t\tglobal_step = tf.contrib.framework.get_or_create_global_step()\n",
        "\t\tif ckpt and ckpt.model_checkpoint_path:\n",
        "\t\t\t# Restores from checkpoint\n",
        "\t\t\tglobal_step_init = int(ckpt.model_checkpoint_path.split('/')[-1]\n",
        "\t\t\t\t\t\t\t\t   .split('-')[-1])\n",
        "\n",
        "\t\t\n",
        "\t\timages, labels, i_paths = mainutils.inputs(eval_data=FLAGS.eval_data,sessid=sessid)\n",
        "\t\t\n",
        "\t\ts_fuse, encoding = mainutils.inference_bottleneck(images)\n",
        "\t\tmainutils.get_show_preds(s_fuse)\n",
        "\n",
        "\n",
        "\n",
        "\t\t# Calculate loss.\n",
        "\t\tsegments_labels = labels\n",
        "\t\twith tf.variable_scope('{}_cross_entropy'.format('s')) as scope:\n",
        "\t\t\tclass_prop = mainutils.S_CLASS_PROP\n",
        "\t\t\tweight_per_label = tf.scalar_mul(class_prop, tf.cast(tf.equal(segments_labels, 0),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t tf.float32)) + \\\n",
        "\t\t\t\t\t\t\t   tf.scalar_mul(1.0 - class_prop, tf.cast(tf.equal(segments_labels, 1),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   tf.float32))\n",
        "\t\t\tcross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
        "\t\t\t\tlabels=tf.squeeze(segments_labels, squeeze_dims=[3]), logits=s_fuse)\n",
        "\t\t\tcross_entropy_weighted = tf.multiply(weight_per_label, cross_entropy)\n",
        "\t\t\tcross_entropy_mean = tf.reduce_mean(cross_entropy_weighted, name=scope.name)\n",
        "\n",
        "\t\tloss = cross_entropy_mean\n",
        "\n",
        "\t\t# Build a Graph that trains the model with one batch of examples and\n",
        "\t\t# updates the model parameters.\n",
        "\t\ttrain_op = mainutils.train(loss, global_step)\n",
        "\n",
        "\t\tclass _LoggerHook(tf.train.SessionRunHook):\n",
        "\t\t\t\"\"\"Logs loss and runtime.\"\"\"\n",
        "\n",
        "\t\t\tdef begin(self):\n",
        "\t\t\t\tself._step = global_step_init\n",
        "\t\t\t\tself._start_time = time.time()\n",
        "\n",
        "\t\t\tdef before_run(self, run_context):\n",
        "\t\t\t\tself._step += 1\n",
        "\t\t\t\treturn tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
        "\n",
        "\t\t\tdef after_run(self, run_context, run_values):\n",
        "\t\t\t\tif self._step % FLAGS.log_frequency == 0:\n",
        "\t\t\t\t\tcurrent_time = time.time()\n",
        "\t\t\t\t\tduration = current_time - self._start_time\n",
        "\t\t\t\t\tself._start_time = current_time\n",
        "\n",
        "\t\t\t\t\tloss_value = run_values.results\n",
        "\t\t\t\t\texamples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
        "\t\t\t\t\tsec_per_batch = float(duration / FLAGS.log_frequency)\n",
        "\n",
        "\t\t\t\t\tformat_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
        "\t\t\t\t\t\t\t\t  'sec/batch)')\n",
        "\t\t\t\t\tprint(format_str % (datetime.now(), self._step, loss_value,\n",
        "\t\t\t\t\t\t\t\t\t\texamples_per_sec, sec_per_batch))\n",
        "\n",
        "\t\tsaver = tf.train.Saver()\n",
        "\t\twith tf.train.MonitoredTrainingSession(\n",
        "\t\t\t\tcheckpoint_dir=FLAGS.train_dir,\n",
        "\t\t\t\thooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
        "\t\t\t\t\t   tf.train.NanTensorHook(loss),\n",
        "\t\t\t\t\t   _LoggerHook()],\n",
        "\t\t\t\tconfig=tf.ConfigProto(\n",
        "\t\t\t\t\tlog_device_placement=FLAGS.log_device_placement)\n",
        "\t\t\t\t) as mon_sess:\n",
        "\t\t\tckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
        "\n",
        "\t\t\tif ckpt:\n",
        "\t\t\t\tsaver.restore(mon_sess, ckpt.model_checkpoint_path)\n",
        "\t\t\t\tlogging.info(\"Model restored from file: %s\" % ckpt.model_checkpoint_path)\n",
        "\t\t\twhile not mon_sess.should_stop():\n",
        "\t\t\t\t_,losseval = mon_sess.run([train_op,loss])\n",
        "\n",
        "def main(argv=None):  # pylint: disable=unused-argument\n",
        "\tFLAGS.train_dir = '/tmp/warwick_train_0'\n",
        "\ttrain(0)\n",
        "\tFLAGS.train_dir = '/tmp/warwick_train_1'\n",
        "\ttrain(1)\n",
        "\tFLAGS.train_dir = '/tmp/warwick_train_2'\n",
        "\ttrain(2)\n",
        "\tFLAGS.train_dir = '/tmp/warwick_train_3'\n",
        "\ttrain(3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0912 01:08:04.647044 140003161491328 deprecation.py:323] From <ipython-input-7-10441686e255>:32: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0912 01:08:04.666014 140003161491328 deprecation.py:323] From data_input.py:119: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W0912 01:08:04.676755 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W0912 01:08:04.682311 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "W0912 01:08:04.688250 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:199: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0912 01:08:04.693414 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0912 01:08:04.700812 140003161491328 deprecation.py:323] From data_input.py:33: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
            "W0912 01:08:04.706202 140003161491328 deprecation_wrapper.py:119] From data_input.py:36: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
            "\n",
            "W0912 01:08:04.711966 140003161491328 deprecation_wrapper.py:119] From data_input.py:39: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\n",
            "\n",
            "W0912 01:08:04.899502 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0912 01:08:04.909679 140003161491328 deprecation.py:323] From data_input.py:70: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0912 01:08:04.920416 140003161491328 deprecation_wrapper.py:119] From data_input.py:73: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0912 01:08:04.928040 140003161491328 deprecation_wrapper.py:119] From mainutils.py:333: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0912 01:08:04.929008 140003161491328 deprecation.py:323] From mainutils.py:334: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "W0912 01:08:05.053004 140003161491328 deprecation.py:323] From mainutils.py:335: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "W0912 01:08:05.111196 140003161491328 deprecation.py:323] From mainutils.py:337: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0912 01:08:05.117193 140003161491328 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0912 01:08:06.562875 140003161491328 deprecation.py:506] From mainutils.py:172: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0912 01:08:06.564239 140003161491328 deprecation_wrapper.py:119] From mainutils.py:173: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0912 01:08:06.581993 140003161491328 deprecation_wrapper.py:119] From mainutils.py:69: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0912 01:08:06.584722 140003161491328 deprecation_wrapper.py:119] From mainutils.py:70: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0912 01:08:07.081387 140003161491328 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "W0912 01:08:07.150552 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0912 01:08:07.162580 140003161491328 deprecation_wrapper.py:119] From mainutils.py:418: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0912 01:08:07.170609 140003161491328 deprecation_wrapper.py:119] From mainutils.py:389: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0912 01:08:07.189666 140003161491328 deprecation_wrapper.py:119] From mainutils.py:430: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0912 01:08:09.079014 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/moving_averages.py:433: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0912 01:08:12.822262 140003161491328 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0912 01:08:15.673016 140003161491328 monitored_session.py:240] Graph was finalized.\n",
            "I0912 01:08:22.704803 140003161491328 session_manager.py:500] Running local_init_op.\n",
            "I0912 01:08:22.838978 140003161491328 session_manager.py:502] Done running local_init_op.\n",
            "W0912 01:08:23.421865 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "I0912 01:08:34.693634 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/warwick_train_0/model.ckpt.\n",
            "W0912 01:08:36.596096 140003161491328 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0912 01:08:37.235896 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_0/model.ckpt-0\n",
            "I0912 01:08:43.065541 140003161491328 <ipython-input-7-10441686e255>:104] Model restored from file: /tmp/warwick_train_0/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:08:43.065151: step 0, loss = 0.76 (7.0 examples/sec; 0.142 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0912 01:08:45.760337 140003161491328 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "I0912 01:08:52.533031 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 10.5592\n",
            "I0912 01:08:58.047202 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.1352\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:08:58.057214: step 200, loss = 0.23 (13.3 examples/sec; 0.075 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:03.532685 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.2299\n",
            "I0912 01:09:09.031238 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.1867\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:09:09.044832: step 400, loss = 0.21 (18.2 examples/sec; 0.055 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:14.509032 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.2554\n",
            "I0912 01:09:19.961035 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.3419\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:09:19.974593: step 600, loss = 0.09 (18.3 examples/sec; 0.055 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:25.471681 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.1466\n",
            "I0912 01:09:30.935482 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.3025\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:09:30.952273: step 800, loss = 0.24 (18.2 examples/sec; 0.055 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:36.548331 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8162\n",
            "I0912 01:09:42.048429 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.1816\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:09:42.067445: step 1000, loss = 0.25 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:47.601892 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0066\n",
            "I0912 01:09:53.200054 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.863\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:09:53.214252: step 1200, loss = 0.07 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:09:58.801064 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8539\n",
            "I0912 01:10:04.408154 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8346\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:10:04.419949: step 1400, loss = 0.10 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:10:09.993618 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9036\n",
            "I0912 01:10:15.568725 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9369\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:10:15.577768: step 1600, loss = 0.08 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:10:21.270555 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5383\n",
            "I0912 01:10:26.976303 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5263\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:10:26.987311: step 1800, loss = 0.13 (17.5 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:10:32.641315 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6522\n",
            "I0912 01:10:38.258716 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8018\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:10:38.271707: step 2000, loss = 0.13 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:10:43.927563 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6402\n",
            "I0912 01:10:49.514596 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8986\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:10:49.523506: step 2200, loss = 0.05 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:10:55.183058 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6416\n",
            "I0912 01:11:00.823709 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7284\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:00.839480: step 2400, loss = 0.05 (17.7 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:11:06.455553 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7562\n",
            "I0912 01:11:12.138652 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.596\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:12.158366: step 2600, loss = 0.07 (17.7 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:11:17.832751 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5621\n",
            "I0912 01:11:23.484127 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6948\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:23.497250: step 2800, loss = 0.10 (17.6 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:11:29.165601 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.601\n",
            "I0912 01:11:34.763164 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.865\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:34.774203: step 3000, loss = 0.09 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:11:40.340821 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9286\n",
            "I0912 01:11:46.043689 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5351\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:46.054505: step 3200, loss = 0.04 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:11:51.779654 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.4339\n",
            "I0912 01:11:57.378618 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8604\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:11:57.392169: step 3400, loss = 0.02 (17.6 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:12:02.999541 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7907\n",
            "I0912 01:12:08.645642 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7114\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:12:08.657776: step 3600, loss = 0.02 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:12:14.233185 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8969\n",
            "I0912 01:12:19.857877 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7787\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:12:19.866011: step 3800, loss = 0.06 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:12:25.428726 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9506\n",
            "I0912 01:12:31.046104 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8019\n",
            "I0912 01:12:31.061553 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /tmp/warwick_train_0/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:12:31.060288: step 4000, loss = 0.02 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:12:40.748964 140003161491328 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0912 01:12:43.876859 140003161491328 monitored_session.py:240] Graph was finalized.\n",
            "I0912 01:12:47.518863 140003161491328 session_manager.py:500] Running local_init_op.\n",
            "I0912 01:12:47.687732 140003161491328 session_manager.py:502] Done running local_init_op.\n",
            "I0912 01:12:59.388818 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/warwick_train_1/model.ckpt.\n",
            "I0912 01:13:01.374125 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_1/model.ckpt-0\n",
            "I0912 01:13:03.113915 140003161491328 <ipython-input-7-10441686e255>:104] Model restored from file: /tmp/warwick_train_1/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:13:03.113367: step 0, loss = 0.40 (9.8 examples/sec; 0.102 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0912 01:13:04.437176 140003161491328 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "I0912 01:13:11.537925 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 11.8633\n",
            "I0912 01:13:17.198328 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:13:17.218424: step 200, loss = 0.30 (14.2 examples/sec; 0.071 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:13:22.882258 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5935\n",
            "I0912 01:13:28.520447 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7362\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:13:28.531822: step 400, loss = 0.18 (17.7 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:13:34.245565 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.4668\n",
            "I0912 01:13:39.939724 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5619\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:13:39.956154: step 600, loss = 0.18 (17.5 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:13:45.661493 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.4772\n",
            "I0912 01:13:51.302911 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.726\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:13:51.314158: step 800, loss = 0.12 (17.6 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:13:56.960258 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6761\n",
            "I0912 01:14:02.606767 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.71\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:02.619796: step 1000, loss = 0.11 (17.7 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:14:08.270433 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6565\n",
            "I0912 01:14:13.878591 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.831\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:13.887520: step 1200, loss = 0.07 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:14:19.529700 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6956\n",
            "I0912 01:14:25.139626 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8257\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:25.150539: step 1400, loss = 0.12 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:14:30.840909 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5399\n",
            "I0912 01:14:36.493396 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6913\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:36.512151: step 1600, loss = 0.07 (17.6 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:14:42.147623 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6859\n",
            "I0912 01:14:47.756057 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8303\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:47.766853: step 1800, loss = 0.05 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:14:53.417850 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6623\n",
            "I0912 01:14:59.027440 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8266\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:14:59.037920: step 2000, loss = 0.05 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:15:04.634454 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8349\n",
            "I0912 01:15:10.180248 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0317\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:15:10.192702: step 2200, loss = 0.06 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:15:15.799606 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7956\n",
            "I0912 01:15:21.432292 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7536\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:15:21.441668: step 2400, loss = 0.12 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:15:27.068782 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7416\n",
            "I0912 01:15:32.685918 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8027\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:15:32.696989: step 2600, loss = 0.05 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:15:38.313399 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7699\n",
            "I0912 01:15:43.962490 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7018\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:15:43.971646: step 2800, loss = 0.03 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:15:49.550466 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8955\n",
            "I0912 01:15:55.163038 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8172\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:15:55.173156: step 3000, loss = 0.06 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:16:00.764755 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8516\n",
            "I0912 01:16:06.335813 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9499\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:16:06.347240: step 3200, loss = 0.03 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:16:11.905324 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9549\n",
            "I0912 01:16:17.452440 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0275\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:16:17.464184: step 3400, loss = 0.05 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:16:23.163815 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.5088\n",
            "I0912 01:16:28.923471 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.3622\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:16:28.935467: step 3600, loss = 0.06 (17.4 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:16:34.493918 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9519\n",
            "I0912 01:16:40.149780 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6808\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:16:40.158124: step 3800, loss = 0.04 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:16:45.811732 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6618\n",
            "I0912 01:16:51.437252 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7762\n",
            "I0912 01:16:51.448827 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /tmp/warwick_train_1/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:16:51.447763: step 4000, loss = 0.03 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:17:01.458460 140003161491328 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0912 01:17:04.643770 140003161491328 monitored_session.py:240] Graph was finalized.\n",
            "I0912 01:17:08.337812 140003161491328 session_manager.py:500] Running local_init_op.\n",
            "I0912 01:17:08.495752 140003161491328 session_manager.py:502] Done running local_init_op.\n",
            "I0912 01:17:20.427140 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/warwick_train_2/model.ckpt.\n",
            "I0912 01:17:22.822309 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_2/model.ckpt-0\n",
            "I0912 01:17:24.530262 140003161491328 <ipython-input-7-10441686e255>:104] Model restored from file: /tmp/warwick_train_2/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:17:24.527742: step 0, loss = 0.40 (9.6 examples/sec; 0.105 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0912 01:17:25.844295 140003161491328 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "I0912 01:17:33.044254 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 11.7376\n",
            "I0912 01:17:38.766993 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.4737\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:17:38.777162: step 200, loss = 0.27 (14.0 examples/sec; 0.071 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:17:44.351615 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9066\n",
            "I0912 01:17:49.967406 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8067\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:17:49.978789: step 400, loss = 0.27 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:17:55.614872 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.707\n",
            "I0912 01:18:01.265331 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6978\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:01.277015: step 600, loss = 0.09 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:18:06.892591 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7705\n",
            "I0912 01:18:12.499646 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8347\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:12.509022: step 800, loss = 0.13 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:18:18.096103 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8685\n",
            "I0912 01:18:23.660577 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9712\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:23.672478: step 1000, loss = 0.07 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:18:29.223524 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.976\n",
            "I0912 01:18:34.787045 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9743\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:34.795735: step 1200, loss = 0.14 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:18:40.395030 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8316\n",
            "I0912 01:18:45.940984 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0312\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:45.949500: step 1400, loss = 0.08 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:18:51.495987 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0018\n",
            "I0912 01:18:57.034440 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0556\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:18:57.045074: step 1600, loss = 0.09 (18.0 examples/sec; 0.055 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:02.594156 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9865\n",
            "I0912 01:19:08.165497 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.949\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:19:08.176521: step 1800, loss = 0.05 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:13.767296 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8514\n",
            "I0912 01:19:19.392303 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7777\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:19:19.403469: step 2000, loss = 0.04 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:24.958504 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9655\n",
            "I0912 01:19:30.540512 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9148\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:19:30.549186: step 2200, loss = 0.03 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:36.110497 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9533\n",
            "I0912 01:19:41.707200 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8678\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:19:41.716913: step 2400, loss = 0.03 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:47.291858 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.906\n",
            "I0912 01:19:52.886800 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8733\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:19:52.894206: step 2600, loss = 0.11 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:19:58.444437 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9932\n",
            "I0912 01:20:04.004359 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.986\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:04.012175: step 2800, loss = 0.02 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:20:09.566281 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9794\n",
            "I0912 01:20:15.103280 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0604\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:15.111182: step 3000, loss = 0.04 (18.0 examples/sec; 0.055 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:20:20.680514 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.93\n",
            "I0912 01:20:26.249521 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9566\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:26.258524: step 3200, loss = 0.02 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:20:31.843365 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8767\n",
            "I0912 01:20:37.405282 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9794\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:37.414359: step 3400, loss = 0.06 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:20:42.980199 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9374\n",
            "I0912 01:20:48.544258 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9725\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:48.553073: step 3600, loss = 0.04 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:20:54.115966 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9478\n",
            "I0912 01:20:59.653199 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0597\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:20:59.665576: step 3800, loss = 0.04 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:21:05.232506 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9233\n",
            "I0912 01:21:10.840320 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8323\n",
            "I0912 01:21:10.850857 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /tmp/warwick_train_2/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:21:10.849916: step 4000, loss = 0.02 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:21:21.017328 140003161491328 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0912 01:21:24.266756 140003161491328 monitored_session.py:240] Graph was finalized.\n",
            "I0912 01:21:27.977133 140003161491328 session_manager.py:500] Running local_init_op.\n",
            "I0912 01:21:28.136687 140003161491328 session_manager.py:502] Done running local_init_op.\n",
            "I0912 01:21:39.837306 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/warwick_train_3/model.ckpt.\n",
            "I0912 01:21:42.668946 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_3/model.ckpt-0\n",
            "I0912 01:21:44.381439 140003161491328 <ipython-input-7-10441686e255>:104] Model restored from file: /tmp/warwick_train_3/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:21:44.379241: step 0, loss = 0.14 (9.4 examples/sec; 0.106 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0912 01:21:45.696412 140003161491328 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "I0912 01:21:52.842586 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 11.8091\n",
            "I0912 01:21:58.567528 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.4675\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:21:58.576538: step 200, loss = 0.26 (14.1 examples/sec; 0.071 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:22:04.175560 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8316\n",
            "I0912 01:22:09.794998 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7953\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:22:09.803561: step 400, loss = 0.38 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:22:15.448508 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6881\n",
            "I0912 01:22:21.120403 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:22:21.128388: step 600, loss = 0.15 (17.7 examples/sec; 0.057 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:22:26.756345 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7431\n",
            "I0912 01:22:32.370337 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8127\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:22:32.380927: step 800, loss = 0.19 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:22:37.994638 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7799\n",
            "I0912 01:22:43.618664 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7808\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:22:43.626808: step 1000, loss = 0.07 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:22:49.184187 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9678\n",
            "I0912 01:22:54.737246 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0081\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:22:54.746771: step 1200, loss = 0.14 (18.0 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:00.321297 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9082\n",
            "I0912 01:23:05.928579 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8339\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:23:05.936134: step 1400, loss = 0.09 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:11.557049 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7668\n",
            "I0912 01:23:17.113862 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9959\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:23:17.124117: step 1600, loss = 0.05 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:22.779309 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.651\n",
            "I0912 01:23:28.405742 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7732\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:23:28.416322: step 1800, loss = 0.07 (17.7 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:33.975071 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9556\n",
            "I0912 01:23:39.605736 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7598\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:23:39.614710: step 2000, loss = 0.11 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:45.187599 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9152\n",
            "I0912 01:23:50.819459 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7561\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:23:50.828305: step 2200, loss = 0.04 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:23:56.451927 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7542\n",
            "I0912 01:24:02.049396 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8653\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:02.057308: step 2400, loss = 0.08 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:24:07.610414 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9822\n",
            "I0912 01:24:13.215508 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8409\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:13.227141: step 2600, loss = 0.04 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:24:18.834142 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.798\n",
            "I0912 01:24:24.442481 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8306\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:24.454017: step 2800, loss = 0.03 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:24:29.991731 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 18.0204\n",
            "I0912 01:24:35.615181 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7827\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:35.622319: step 3000, loss = 0.04 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:24:41.229057 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.813\n",
            "I0912 01:24:46.822597 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8778\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:46.835776: step 3200, loss = 0.03 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:24:52.397387 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.9379\n",
            "I0912 01:24:58.011826 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8111\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:24:58.022815: step 3400, loss = 0.02 (17.9 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:25:03.634033 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7867\n",
            "I0912 01:25:09.266921 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.7529\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:25:09.278294: step 3600, loss = 0.06 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:25:14.847588 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.919\n",
            "I0912 01:25:20.502160 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.6849\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:25:20.511581: step 3800, loss = 0.04 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 01:25:26.117115 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8095\n",
            "I0912 01:25:31.730911 140003161491328 basic_session_run_hooks.py:692] global_step/sec: 17.8133\n",
            "I0912 01:25:31.744002 140003161491328 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into /tmp/warwick_train_3/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-12 01:25:31.743053: step 4000, loss = 0.04 (17.8 examples/sec; 0.056 sec/batch)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0562PwLNTxyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UssLKnFIDSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "import math\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import mainutils\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "# tf.app.flags.DEFINE_string('eval_dir', '/tmp/warwick_eval',\n",
        "# \t\t\t\t\t\t   \"\"\"Directory where to write event logs.\"\"\")\n",
        "# tf.app.flags.DEFINE_string('eval_data', 'train_eval',\n",
        "# \t\t\t\t\t\t   \"\"\"Either 'test' or 'train' or 'train_eval'.\"\"\")\n",
        "# tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/warwick_train/',\n",
        "# \t\t\t\t\t\t   \"\"\"Directory where to read model checkpoints.\"\"\")\n",
        "# tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
        "# \t\t\t\t\t\t\t\"\"\"How often to run the eval.\"\"\")\n",
        "# tf.app.flags.DEFINE_integer('num_examples', 100,\n",
        "# \t\t\t\t\t\t\t\"\"\"Number of examples to run.\"\"\")\n",
        "# tf.app.flags.DEFINE_boolean('run_once', True,\n",
        "# \t\t\t\t\t\t\t\"\"\"Whether to run eval only once.\"\"\")\n",
        "\n",
        "\n",
        "def eval_once(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid):\n",
        "\t\"\"\"Run Eval once.\n",
        "\tArgs:\n",
        "\t\tsaver: Saver.\n",
        "\t\tsummary_writer: Summary writer.\n",
        "\t\tsummary_op: Summary op.\n",
        "\t\"\"\"\n",
        "\n",
        "\tFLAGS.checkpoint_dir = '/tmp/warwick_train_'+str(sessid)\n",
        "\twith tf.Session() as sess:\n",
        "\t\tckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
        "\t\tif ckpt and ckpt.model_checkpoint_path:\n",
        "\t\t\t# Restores from checkpoint\n",
        "\t\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\t\t\tprint(\"Model restored from file: %s\" % ckpt.model_checkpoint_path)\n",
        "\t\t\tglobal_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
        "\t\telse:\n",
        "\t\t\tprint('No checkpoint file found')\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# Start the queue runners.\n",
        "\t\tcoord = tf.train.Coordinator()\n",
        "\t\tpredictions = {}\n",
        "\t\tencodings = {}\n",
        "\t\tdice_scores = {}\n",
        "\t\ttry:\n",
        "\t\t\tthreads = []\n",
        "\t\t\tfor qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
        "\t\t\t\tthreads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t start=True))\n",
        "\n",
        "\t\t\tnum_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
        "\t\t\tavg_s_dice = 0\n",
        "\t\t\tstep = 0\n",
        "\t\t\twhile step < num_iter and not coord.should_stop():\n",
        "\t\t\t\ts_dice,i_path,s_fuse_out,encoded_image = sess.run([dice_op,i_paths,s_fuse,encoding])\n",
        "\t\t\t\tpredictions[i_path[0]] = s_fuse_out\n",
        "\t\t\t\tencodings[i_path[0]] = encoded_image\n",
        "\t\t\t\tdice_scores[i_path[0]] = s_dice\n",
        "\t\t\t\tim0 = s_fuse_out[0,:,:,0]\n",
        "\t\t\t\tim1 = s_fuse_out[0,:,:,1]\n",
        "\t\t\t\timage = (im1>im0)*128\n",
        "\t\t\t\tim = Image.fromarray(image.astype(np.uint8))\n",
        "        \n",
        "\t\t\t\tim.save('reshaped_warwick/results/'+i_path[0].split('/')[2])\n",
        "\t\t\t\tavg_s_dice += s_dice\n",
        "\t\t\t\tstep += 1\n",
        "\n",
        "\t\t\tavg_s_dice /= step\n",
        "\t\t\tprint('%s: s_dice avg = %.3f' % (datetime.now(), avg_s_dice))\n",
        "\n",
        "\t\t\tsummary = tf.Summary()\n",
        "\t\t\tsummary.ParseFromString(sess.run(summary_op))\n",
        "\t\t\tsummary.value.add(tag='dice_s', simple_value=avg_s_dice)\n",
        "\t\t\tsummary_writer.add_summary(summary, global_step)\n",
        "\t\texcept Exception as e:  # pylint: disable=broad-except\n",
        "\t\t\tcoord.request_stop(e)\n",
        "\t\tif FLAGS.eval_data == 'train_eval':\n",
        "\t\t\tnp.save('train_eval_data_'+str(sessid)+'.npy',[predictions, encodings, dice_scores]) # otherwise don't save\n",
        "\t\tcoord.request_stop()\n",
        "\t\tcoord.join(threads, stop_grace_period_secs=20)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRxlpHrgJchL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "d50d293b-a411-46f2-9f0d-fffb094365f3"
      },
      "source": [
        "def evaluate():\n",
        "\t\n",
        "\tfor sessid in range(4):\n",
        "\t\tFLAGS.eval_dir = '/tmp/warwick_eval_' + str(sessid)\n",
        "\t\twith tf.Graph().as_default() as g:\n",
        "\t\t\t# Get images and labels for BBBC006.\n",
        "\t\t\timages, labels, i_paths = mainutils.inputs(eval_data=FLAGS.eval_data, sessid=sessid)\n",
        "\t\t\t\n",
        "\t\t\t# Build a Graph that computes the logits predictions from the\n",
        "\t\t\t\n",
        "\t\t\ts_fuse, encoding = mainutils.inference_bottleneck(images, train=False)\n",
        "\n",
        "\t\t\tdice_op = mainutils.dice_op(s_fuse, labels)\n",
        "\n",
        "\t\t\t# Restore the moving average version of the learned variables for eval.\n",
        "\t\t\tvariable_averages = tf.train.ExponentialMovingAverage(\n",
        "\t\t\t\tmainutils.MOVING_AVERAGE_DECAY)\n",
        "\t\t\tvariables_to_restore = variable_averages.variables_to_restore()\n",
        "\t\t\tsaver = tf.train.Saver(variables_to_restore)\n",
        "\n",
        "\t\t\t# Build the summary operation based on the TF collection of Summaries.\n",
        "\t\t\tsummary_op = tf.summary.merge_all()\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n",
        "\t\t\ts_fuse_softmax = tf.nn.softmax(s_fuse)\n",
        "\n",
        "\t\t\twhile True:\n",
        "\t\t\t\teval_once(saver, dice_op, summary_writer, summary_op, s_fuse_softmax, images, labels, i_paths, encoding, sessid)\n",
        "\t\t\t\tif FLAGS.run_once:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\ttime.sleep(FLAGS.eval_interval_secs)\n",
        "\n",
        "\n",
        "def main(argv=None):  # pylint: disable=unused-argument\n",
        "\tif tf.gfile.Exists(FLAGS.eval_dir):\n",
        "\t\ttf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
        "\ttf.gfile.MakeDirs(FLAGS.eval_dir)\n",
        "\tevaluate()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0912 02:06:06.202944 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_0/model.ckpt-4000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model restored from file: /tmp/warwick_train_0/model.ckpt-4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 02:06:07.208344 140003161491328 coordinator.py:224] Error reported to Coordinator: <type 'exceptions.IOError'>, [Errno 2] No such file or directory: 'reshaped_warwick/results/train_30.png'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IOError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-401b658e52b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-401b658e52b9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-401b658e52b9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                 \u001b[0meval_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_fuse_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msessid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_once\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-8a7d62d1a0d8>\u001b[0m in \u001b[0;36meval_once\u001b[0;34m(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_eval_data_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# otherwise don't save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_grace_period_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-8a7d62d1a0d8>\u001b[0m in \u001b[0;36meval_once\u001b[0;34m(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                 \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reshaped_warwick/results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                                 \u001b[0mavg_s_dice\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms_dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m             \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'reshaped_warwick/results/train_30.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_2TA5P-IDSk",
        "colab_type": "code",
        "outputId": "571cd6e5-70d9-4b75-b24a-41f3dda66f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "import math\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import mainutils\n",
        "\n",
        "# FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "# tf.app.flags.DEFINE_string('eval_dir', '/tmp/warwick_eval',\n",
        "# \t\t\t\t\t\t   \"\"\"Directory where to write event logs.\"\"\")\n",
        "# tf.app.flags.DEFINE_string('eval_data', 'train_eval',\n",
        "# \t\t\t\t\t\t   \"\"\"Either 'test' or 'train' or 'train_eval'.\"\"\")\n",
        "# tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/warwick_train',\n",
        "# \t\t\t\t\t\t   \"\"\"Directory where to read model checkpoints.\"\"\")\n",
        "# tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
        "# \t\t\t\t\t\t\t\"\"\"How often to run the eval.\"\"\")\n",
        "# tf.app.flags.DEFINE_integer('num_examples', 100,\n",
        "# \t\t\t\t\t\t\t\"\"\"Number of examples to run.\"\"\")\n",
        "# tf.app.flags.DEFINE_boolean('run_once', True,\n",
        "# \t\t\t\t\t\t\t\"\"\"Whether to run eval only once.\"\"\")\n",
        "\n",
        "\n",
        "def eval_once(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid):\n",
        "\t\"\"\"Run Eval once.\n",
        "\tArgs:\n",
        "\t\tsaver: Saver.\n",
        "\t\tsummary_writer: Summary writer.\n",
        "\t\tsummary_op: Summary op.\n",
        "\t\"\"\"\n",
        "\n",
        "\tFLAGS.checkpoint_dir = '/tmp/warwick_train_'+str(sessid)\n",
        "\twith tf.Session() as sess:\n",
        "\t\tckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
        "\t\tif ckpt and ckpt.model_checkpoint_path:\n",
        "\t\t\t# Restores from checkpoint\n",
        "\t\t\tsaver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\t\t\tprint(\"Model restored from file: %s\" % ckpt.model_checkpoint_path)\n",
        "\t\t\tglobal_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
        "\t\telse:\n",
        "\t\t\tprint('No checkpoint file found')\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# Start the queue runners.\n",
        "\t\tcoord = tf.train.Coordinator()\n",
        "\t\tpredictions = {}\n",
        "\t\tencodings = {}\n",
        "\t\tdice_scores = {}\n",
        "\t\ttry:\n",
        "\t\t\tthreads = []\n",
        "\t\t\tfor qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
        "\t\t\t\tthreads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t start=True))\n",
        "\n",
        "\t\t\tnum_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
        "\t\t\tavg_s_dice = 0\n",
        "\t\t\tstep = 0\n",
        "\t\t\twhile step < num_iter and not coord.should_stop():\n",
        "\t\t\t\ts_dice,i_path,s_fuse_out,encoded_image = sess.run([dice_op,i_paths,s_fuse,encoding])\n",
        "\t\t\t\tpredictions[i_path[0]] = s_fuse_out\n",
        "\t\t\t\tencodings[i_path[0]] = encoded_image\n",
        "\t\t\t\tdice_scores[i_path[0]] = s_dice\n",
        "\t\t\t\tim0 = s_fuse_out[0,:,:,0]\n",
        "\t\t\t\tim1 = s_fuse_out[0,:,:,1]\n",
        "\t\t\t\timage = (im1>im0)*128\n",
        "\t\t\t\tim = Image.fromarray(image.astype(np.uint8))\n",
        "\t\t\t\tim.save('results/'+i_path[0].split('/')[2]+'.bmp')\n",
        "\t\t\t\tavg_s_dice += s_dice\n",
        "\t\t\t\tstep += 1\n",
        "\n",
        "\t\t\tavg_s_dice /= step\n",
        "\t\t\tprint('%s: s_dice avg = %.3f' % (datetime.now(), avg_s_dice))\n",
        "\n",
        "\t\t\tsummary = tf.Summary()\n",
        "\t\t\tsummary.ParseFromString(sess.run(summary_op))\n",
        "\t\t\tsummary.value.add(tag='dice_s', simple_value=avg_s_dice)\n",
        "\t\t\tsummary_writer.add_summary(summary, global_step)\n",
        "\t\texcept Exception as e:  # pylint: disable=broad-except\n",
        "\t\t\tcoord.request_stop(e)\n",
        "\t\tif FLAGS.eval_data == 'train_eval':\n",
        "\t\t\tnp.save('train_eval_data_'+str(sessid)+'.npy',[predictions, encodings, dice_scores]) # otherwise don't save\n",
        "\t\tcoord.request_stop()\n",
        "\t\tcoord.join(threads, stop_grace_period_secs=20)\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "\t\"\"\"Eval BBBC006 for a number of steps.\"\"\"\n",
        "\tfor sessid in range(4):\n",
        "\t\tFLAGS.eval_dir = '/tmp/warwick_eval_/' + str(sessid)\n",
        "\t\twith tf.Graph().as_default() as g:\n",
        "\t\t\t# Get images and labels for BBBC006.\n",
        "\t\t\timages, labels, i_paths = mainutils.inputs(eval_data=FLAGS.eval_data, sessid=sessid)\n",
        "\t\t\t\n",
        "\t\t\t# Build a Graph that computes the logits predictions from the\n",
        "\t\t\t# inference model.\n",
        "\t\t\t# s_fuse = mainutils.inference(images, train=False)\n",
        "\t\t\ts_fuse, encoding = mainutils.inference_bottleneck(images, train=False)\n",
        "\n",
        "\t\t\tdice_op = mainutils.dice_op(s_fuse, labels)\n",
        "\n",
        "\t\t\t# Restore the moving average version of the learned variables for eval.\n",
        "\t\t\tvariable_averages = tf.train.ExponentialMovingAverage(\n",
        "\t\t\t\tmainutils.MOVING_AVERAGE_DECAY)\n",
        "\t\t\tvariables_to_restore = variable_averages.variables_to_restore()\n",
        "\t\t\tsaver = tf.train.Saver(variables_to_restore)\n",
        "\n",
        "\t\t\t# Build the summary operation based on the TF collection of Summaries.\n",
        "\t\t\tsummary_op = tf.summary.merge_all()\n",
        "\t\t\tsummary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n",
        "\t\t\ts_fuse_softmax = tf.nn.softmax(s_fuse)\n",
        "\n",
        "\t\t\twhile True:\n",
        "\t\t\t\teval_once(saver, dice_op, summary_writer, summary_op, s_fuse_softmax, images, labels, i_paths, encoding, sessid)\n",
        "\t\t\t\tif FLAGS.run_once:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\ttime.sleep(FLAGS.eval_interval_secs)\n",
        "\n",
        "\n",
        "def main(argv=None):  # pylint: disable=unused-argument\n",
        "\tif tf.gfile.Exists(FLAGS.eval_dir):\n",
        "\t\ttf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
        "\ttf.gfile.MakeDirs(FLAGS.eval_dir)\n",
        "\tevaluate()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttf.app.run()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0912 02:00:17.474838 140003161491328 saver.py:1280] Restoring parameters from /tmp/warwick_train_0/model.ckpt-4000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model restored from file: /tmp/warwick_train_0/model.ckpt-4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0912 02:00:18.423402 140003161491328 coordinator.py:224] Error reported to Coordinator: <type 'exceptions.IOError'>, [Errno 2] No such file or directory: 'results/train_30.png.bmp'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IOError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dee4e1949ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dee4e1949ba2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dee4e1949ba2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                                 \u001b[0meval_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_fuse_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msessid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_once\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dee4e1949ba2>\u001b[0m in \u001b[0;36meval_once\u001b[0;34m(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid)\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_eval_data_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# otherwise don't save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_grace_period_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dee4e1949ba2>\u001b[0m in \u001b[0;36meval_once\u001b[0;34m(saver, dice_op, summary_writer, summary_op, s_fuse, images, labels, i_paths, encoding, sessid)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mim0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                                 \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.bmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                                 \u001b[0mavg_s_dice\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms_dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m             \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'results/train_30.png.bmp'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nJRMVbyIDSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import operator\n",
        "\n",
        "predictions, encodings, dice_scores = np.array([None]*4), np.array([None]*4), np.array([None]*4)\n",
        "for i in range(4):\n",
        "\tpredictions[i], encodings[i], dice_scores[i] = np.load('train_eval_data_'+str(i)+'.npy')\n",
        "\n",
        "keys = dice_scores[0].keys()\n",
        "K, k = 20, 10\n",
        "\n",
        "scores = {}\n",
        "for key in keys:\n",
        "\ttotal_array = np.array([\n",
        "\t\t\tpredictions[0][key],\n",
        "\t\t\tpredictions[1][key],\n",
        "\t\t\tpredictions[2][key],\n",
        "\t\t\tpredictions[3][key]\n",
        "\t\t])\n",
        "\tscores[key] = np.sum(np.var(total_array,axis=0))\n",
        "# scores list would have images tuples in decreasing order of variance\n",
        "scores_list = sorted(scores.items(), key=lambda x: -x[1])\n",
        "options_available = [scores_list[i][0] for i in range(K)]\n",
        "\n",
        "def similarity(encodings, key1, key2): # cosine similarity\n",
        "\tsimilarities = [None]*4\n",
        "\tfor i in range(4):\n",
        "\t\tsimilarities[i] = 1 - spatial.distance.cosine(np.mean(encodings[i][key1],axis=3).flatten(),np.mean(encodings[i][key2],axis=3).flatten())\n",
        "\treturn np.mean(similarities)\n",
        "\n",
        "def unit_F(similarities,key,images_selected):\n",
        "\tmax_sim = float('-inf')\n",
        "\tfor image_selected in images_selected:\n",
        "\t\tmax_sim = max(max_sim,similarities[(key,image_selected)])\n",
        "\treturn max_sim\n",
        "\n",
        "def calc_F(similarities,keys,images_selected):\n",
        "\tF = 0\n",
        "\tfor key in keys:\n",
        "\t\tF += unit_F(similarities,key,images_selected)\n",
        "\treturn F\n",
        "\n",
        "similarities = {}\n",
        "for key1 in keys:\n",
        "\tfor key2 in keys:\n",
        "\t\tsimilarities[(key1,key2)] = similarity(encodings,key1,key2)\n",
        "\n",
        "# select first 20 images with highest uncertainity and then select\n",
        "# the 10 representative out of them\n",
        "images_selected = []\n",
        "while len(images_selected) < k:\n",
        "\tF_options = {}\n",
        "\tfor option in options_available:\n",
        "\t\tF_options[option] = calc_F(similarities,keys,images_selected+[option])\n",
        "\tbest_option = max(F_options.iteritems(), key=operator.itemgetter(1))[0]\n",
        "\toptions_available.remove(best_option)\n",
        "\timages_selected.append(best_option)\n",
        "print(images_selected)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etcd9cPkIDSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTNRTQEfIDSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}